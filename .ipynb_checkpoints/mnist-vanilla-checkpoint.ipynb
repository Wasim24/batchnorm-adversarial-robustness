{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls adversarial-robustness-toolbox/\n",
    "import os\n",
    "os.chdir('/home/surthi/adversarial-robustness-toolbox/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import keras.backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "from art.attacks import DeepFool\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, x_train, y_train, x_test, y_test):\n",
    "    # train acc\n",
    "    train_preds = np.argmax(clf.predict(x_train), axis=1)\n",
    "    train_acc = np.sum(train_preds == np.argmax(y_train, axis=1)) / y_train.shape[0]\n",
    "    # test acc\n",
    "    test_preds = np.argmax(clf.predict(x_test), axis=1)\n",
    "    test_acc = np.sum(test_preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "    print(\"\\nTraining and Test accuracies: %.2f %.2f%%\" % (train_acc*100, test_acc*100))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def plot_curves(model, title='model accuracy and loss'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(model.history.history['acc'])\n",
    "    plt.plot(model.history.history['loss'])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Accuracy', 'Loss'], loc='upper left')\n",
    "    return plt\n",
    "\n",
    "def save_clf(c, folder, clf_filename, model_filename):\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(folder)\n",
    "    import pickle\n",
    "    with open(clf_filename, \"wb\") as f:\n",
    "        pickle.dump(c.__getstate__, f)\n",
    "    c._model.save(model_filename)\n",
    "    os.chdir(cwd)\n",
    "\n",
    "DUMP_FOLDER = '/home/surthi/models/'\n",
    "def pickle_dump(data, filename, folder=DUMP_FOLDER):\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(folder)\n",
    "    print(os.getcwd())\n",
    "    import pickle\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    os.chdir(cwd)\n",
    "\n",
    "def pickle_load(filename):\n",
    "    import pickle\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def load_clf(folder, clf_filename, model_filename):\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(folder)\n",
    "    import pickle\n",
    "    with open(clf_filename, \"rb\") as f:\n",
    "        clf_state = pickle.load(f)\n",
    "    model = tf.keras.models.load_model(model_filename)\n",
    "    os.chdir(cwd)\n",
    "    clf = KerasClassifier(model=model)\n",
    "    clf.__setstate__(clf_state())\n",
    "    return clf, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vanilla_model(x_train, y_train, batch_norm=False):\n",
    "    m = Sequential()\n",
    "\n",
    "    m.add(Conv2D(64, (3, 3), padding='valid', input_shape=(28, 28, 1)))\n",
    "    m.add(Activation('relu'))\n",
    "    if(batch_norm):\n",
    "        m.add(BatchNormalization())\n",
    "    m.add(Conv2D(64, (3, 3)))\n",
    "    m.add(Activation('relu'))\n",
    "    if(batch_norm):\n",
    "        m.add(BatchNormalization())\n",
    "    m.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Flatten())\n",
    "    m.add(Dense(128))         \n",
    "    m.add(Activation('relu'))\n",
    "    if(batch_norm):\n",
    "        m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(10))\n",
    "    m.add(Activation('softmax'))\n",
    "    m.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    c = KerasClassifier(model=m)\n",
    "    c.fit(x_train, y_train, nb_epochs=50, batch_size=128)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN MODEL WITH BATCHNORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3298: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1788 - acc: 0.9471\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0651 - acc: 0.9798\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0531 - acc: 0.9839\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0447 - acc: 0.9865\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0410 - acc: 0.9870\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0357 - acc: 0.9888\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0325 - acc: 0.9900\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0319 - acc: 0.9896\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0297 - acc: 0.9906\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0269 - acc: 0.9919\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0226 - acc: 0.9927\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0209 - acc: 0.9933\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0198 - acc: 0.9934\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0183 - acc: 0.9938\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0181 - acc: 0.9935\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0174 - acc: 0.9947\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0155 - acc: 0.9949\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0150 - acc: 0.9948\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0151 - acc: 0.9950\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0131 - acc: 0.9956\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0126 - acc: 0.9960\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0124 - acc: 0.9960\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0130 - acc: 0.9956\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0118 - acc: 0.9959\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0122 - acc: 0.9960\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0109 - acc: 0.9961\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0102 - acc: 0.9966\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0079 - acc: 0.9973\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0086 - acc: 0.9970\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0075 - acc: 0.9974\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0079 - acc: 0.9975\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0085 - acc: 0.9970\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0086 - acc: 0.9970\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0079 - acc: 0.9970\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0083 - acc: 0.9971\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0069 - acc: 0.9975\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0082 - acc: 0.9972\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0063 - acc: 0.9977\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0078 - acc: 0.9973\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_with_bn = get_vanilla_model(x_train, y_train, batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf_with_bn, '/home/surthi/models/mnist/', 'vanilla_clf_with_bn.h5', 'vanilla_clf_with_bn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99995, 0.9932)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(vanilla_clf_with_bn, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYHGWd9vHv3T0zmZwM5AACSUiAKLDIcZYo6AoEV0AF0ZWDyAK6cukqBEF30ZdVFl13WX09IYqogLAIBA/ZvIqiC2FdFJUgghJkCSGYhEBCQkJCmMxM9+/946meqQyTTCfM0Jma+3NddVV1VXXXU9Xddz31VHeVIgIzMyuWUqMLYGZmA8/hbmZWQA53M7MCcribmRWQw93MrIAc7mZmBeRwtwEj6TpJn6lz3iWSjh3sMg0XkqZJCklNW5ju7T3MONzNzArI4W7Wy5Zqv2ZDicN9mMkOzz8m6UFJz0v6tqRdJf1E0npJ/yVp59z8J0p6SNJaSXdJ2i837RBJv8uedwvQ2mtZb5X0++y5v5J0YJ1lfIuk+yU9J2mppEt7TX999nprs+lnZ+NHSvq/kp6QtE7S3dm4oyQt62M7HJsNXyrpe5L+Q9JzwNmSDpd0T7aMFZK+Kqkl9/y/kPRzSWskPS3pE5JeKWmjpAm5+Q6VtEpScx/r2d8yQtIHJD2azXOlJGXTypI+L+kZSYuBt9SzbbPnjpD0JUlPZt2XJI3Ipk2U9KNseWsk/Y+kUjbtHyUtz97vRyTNqneZ1gAR4W4YdcAS4NfArsAewErgd8AhpHC+E/hUNu+rgOeBNwHNwD8Ai4CWrHsC+Eg27W+ATuAz2XMPyV57JlAGzsqWPSJXjmO3UMajgNeQKh8HAk8Db8+m7QmsB07PljsBODibdiVwV7ZeZeAIYET2esv62A7HZsOXZmV/e7bMkcBhwGuBJmAa8DBwQTb/WGAFcFG2zcYCM7NptwEfzC3ni8AVW1jPLS4jmx7Aj4CdgKnAKuC4bNoHgD8BU4DxwPxs/qatvO+19b0s+wzsAkwCfgV8Opv2r8BV2bZtBt4ACHg1sBTYPZtvGrB3oz/P7rbyXW90Ady9zG94+pKfkXv8feDrucfnAXOz4X8C5uSmlYDlWVj+FfAkoNz0X9ET7l+vBUZu+iPAG3Pl6DPc+yjzl4AvZsMfB37Yxzwl4AXgoD6m1RPuv+inDBfUlkvasdy/hflOBX6ZDZeBp4DD61zPC/LrloX163OP5wAXZ8N3Ah/ITfvrbQj3x4ATctPeDCzJhi8D/hPYp9fz9yHtrI8Fmhv9OXbXf+dmmeHp6dzwC308HpMN706qnQMQEVVS7W2PbNryyL75mSdyw3sCF2WH92slrSXVMnfvr3CSZkqanzVnrCPVUidmk6eQwqm3iaRadF/T6rG0VxlelTVPPJU11Xy2jjJACsb9JU0nHfGsi4jf9jVjP8uoeSo3vJHN35t8mfPbvj+bva/ZcO19+Rzp6OxnkhZLuhggIhaRdj6XAisl3Syp3/fSGsfhblvzJCmkAcjae6eQau8rgD1qbcCZqbnhpcC/RMROuW5URNxUx3K/C8wDpkTEOFIzQW05S4G9+3jOM0D7FqY9D4zKrUeZ1ByR1/vyqF8nNXvMiIhXAJ/oVYa9+ip4RLSTatjvAc4EbuhrvjqW0Z8VpPeiZuqWZuzDZu9r9twnASJifURcFBF7AScCF9ba1iPiuxHx+uy5AVy+Dcu0l5nD3bZmDvAWSbOyE4IXAZtIzS/3AF3A+ZKaJb0DODz33G8CH8hq4ZI0OjtROraO5Y4F1kREu6TDgXfnpt0IHCvpFElNkiZIOjg7qrgG+IKk3bMTjq/LThT+L9CaLb8ZuITUFt9fGZ4DNkjaF/hgbtqPgN0kXZCdnBwraWZu+vXA2aRw3Fq4b20Z/ZlD2vaTlU6AX7wNz70JuETSJEkTgU8C/wHdJ8H3yXba64AKUJX0aknHZNuznXSEV92GZdrLzOFuWxQRj5BqoFeQasZvA94WER0R0QG8gxRia0htzT/IPXcB8H7gq8CzpEP9s+tc9N8Dl0laTwqeObnX/TNwAmlHswb4PXBQNvmjwB+Ae7NplwOliFiXvea3SEcdzwOb/XqmDx8l7VTWk3ZUt+TKsJ7U5PI2UrPJo8DRuem/JAXf7yJia80lW1xGHb4J3A48QDoh/oOtz76ZzwALgAdJ2+t32TiAGcB/ARtIO/CvRcR80s7w30ifg6dIJ2M/vg3LtJeZNm8yNbOBIOlO4LsR8a1Gl8WGJ4e72QCT9JfAz0nnDNY3ujw2PLlZxmwASfoOqVnjAge7NZJr7mZmBeSau5lZATXsAkkTJ06MadOmNWrxZmZD0n333fdMRPT+n8aLNCzcp02bxoIFCxq1eDOzIUlSXf9GdrOMmVkBOdzNzArI4W5mVkA71B1nOjs7WbZsGe3t7Y0uypDV2trK5MmTaW5+0b0hzGwY2aHCfdmyZYwdO5Zp06ax+cUGrR4RwerVq1m2bBnTp09vdHHMrIH6bZaRdI2klZL+uIXpkvQVSYuUbt126PYWpr29nQkTJjjYt5MkJkyY4CMfM6urzf064LitTD+edCW5GcC5pGtUbzcH+0vj7WdmUEezTET8QtK0rcxyEnB9dkeeX0vaSdJuEbFigMpotpmIoLMSVKpBvOgeG0k1oFIJKhF0VatUqkFXJeh9tY38vrBUEmWJUgnKEuWSKJVEVKEakXU9wxHpjhURm79uGh+54VqZgmo1lalSDapVsuEqmzqrbOqqsqmrQntn6m/qqlIuiZZyiZamEiOaUr+lXKaUlbv32leqaX07ulK/qxJ0VqpUIyhl69TdKa1fSaIkKEmQ9UtKZe9Zz1Te2rpXsrJXq0FXNfWDnmWUstcuS0ipXNVsvWtdtfv109ZKr5GWWytjU0k0lUs0lXpet3s7b+G97/szs/n2ivx6VKvd61OpVFG2/qnfs22CoKMSdFWqdFaqdNa2bTUgN5+yz5KU+xxJNJXVvX3+ctrO7LNLPbc22H4D0ea+B5vf7mtZNu5F4S7pXFLtnqlTt+XGMS+vuXPncvLJJ/Pwww+z7777Dvjr18LgxYFB95ekJziA3GO6wyJ6Pe4JlXUvdHLpvIe6v1A9r5M9AahWoauagqUS6QPeVUllqH1IS6WeD7iATV0VXuis0t5ZYVNnCqH2rkoK2VwQ1NYFel5LtfAgBWr3ly1XviA9r7bO1ah9CaGrUqUrC5JKtXtlzIakz7z9gCER7nWLiKuBqwHa2toa9g2t1Ta6qtUUQr0C8Pr/uJHXHnEk3/7ODXzs4/+Uq2kFlVxtIx/KtQuwiZ4AS497QjpfC6pUKpTL5QFdL2ULfn5TFz/43Yru2k9tar5MEjSVSt21o9q8kvrc+UQEI5rKtLaUaW0qsdOoFlqbS7Q2l7trJqJnp9Bzt7ieGl+Q+kSarKxMtfKInuemmlNPTaipXKKpnNXkSiWay6JcKnXXYPMCumulTbka4Itrfj1q72m+RlrbOUqirFptrKeGVurensrWp6dZrLZO5Nattj75mnNteERTiRHNZVqbS4xoKnfX0ivVoKMr1eo7uqp0VFI/f8G/fFNcSWlbNZdFc1bjbS6XKJXUvU61z3Mlt6PMVzJqn+1a7bX7fVXvdYByqdR9tCOlZdRq6LWacRDd70d+nbsrEGizZUnpyKt25FGpfV8r1RfV1ftrhIzcPD2bKQ3UPhe9y9WzPV5cWWkupyOp7m1cStsW2CwT8t+f2pFNJbf9X9E6+L9mG4hwX87m93KcnI1riNqXofYl6Mz6tQ9HV/ah25KNz2/g7rt/ybfmzOP8c07nzA99DElc+7Uv8aMfzKFUKvHGWW/i4k9+muWPP8b/+ehs1qx+hnK5zFXX3ciTy5byja9+metu+j4B/NM/XMiBBx/CqWf8La89aF9Oesff8Iv5d/KhCz7Cxg0buP66a+js6GCvvffmW9dcx+jRo1m1ciXnf/jvWfL44wBc8dUr+dnPbmf8+PHMnj0bCS655BJ23WUXzp89G9g8WB5+biQPXvrmwd7UZpZTqwSU674N7uAaiHCfB3xY0s3ATNLd3l9ye/s//7+HWPjkc3XPX4lgU+fmNRqguw1RwIxdx3Lhm16VteMpq3UAuRrDLTfN4/jjj+OvX3cIu+0yiU0rFvHMM6v49fzb+f199zJq1CjWrFnD+PGjOe0t7+fiiy/m5JNPpr29nWq1Sue6VbQ2l5k8Pt2PeUxrE+PHjGCPnUdSLompu+/Kgw/cD8Dq1av5yHl/D6SwvuXG6znvvPN470c/wjFHH8UF/zmXSqXChg0b2HPqZN7xjndw0YUfoVqtMueWW/jtb3+7WU3UzKym33CXdBNwFDBR0jLgU0AzQERcBdxGuqflImAjcM5gFXZLqhG0d1YoIZqbSpudEMlH39jWJnbfaeRWX+v7t85h9uzZtDaXOf3007jllpuJCM455xxGjUqBPX78eNavX8/y5cs5+eSTgfTnoXqceuqp3cN//OMfueSSS1i7di0bNmzgzW9Ote0777yT66+/HoByucy4ceMYN24cEyZM4P777+fpp5/mkEMOYcKECfVuIjMbZur5tczp/UwP4EMDVqLMp972F3XN90JHhcXPbKBcEntPGkNzefuvqLBmzRruvPNO/vCHPyCJSqWCJN71rnfV/RpNTU1Uqz03he/9m/PRo0d3D5999tnMnTuXgw46iOuuu4677rprq6/9d3/3d1x33XU89dRTvPe97627TGY2/Azpa8u0d1Z4/JnnKUnsNXH0Swp2gO9973uceeaZPPHEEyxZsoSlS5cyffp0xo0bx7XXXsvGjRuBtBMYO3YskydPZu7cuQBs2rSJjRs3sueee7Jw4UI2bdrE2rVrueOOO7a4vPXr17PbbrvR2dnJjTfe2D1+1qxZfP3r6e8ClUqFdevWAXDyySfz05/+lHvvvbe7lm9m1pchG+4dXSnYAaZPHE1L00v/5clNN93U3cxS8853vpMVK1Zw4okn0tbWxsEHH8znP/95AG644Qa+8pWvcOCBB3LEEUfw1FNPMWXKFE455RQOOOAATjnlFA455JAtLu/Tn/40M2fO5Mgjj9zsJ5df/vKXmT9/Pq95zWs47LDDWLhwIQAtLS0cffTRnHLKKQP+SxszK5aG3UO1ra0tet+s4+GHH2a//fbr97mdlSqPrdpApRrsNXEMI1uGR9BVq1UOPfRQbr31VmbMmLHF+erdjmY29Ei6LyLa+ptvyNXcuypVHl/1PF2VYPrE0cMm2BcuXMg+++zDrFmzthrsZmawg10Vsh7PPN9BR6XKtImjGdUy5Iq/3fbff38WL17c6GKY2RAx5NJx17EjGNfaPGxq7GZm22PINctIcrCbmfVjyIW7mZn1z+FuZlZADvdexowZ0+gimJm9ZA53M7MCcrjXYcmSJRxzzDEceOCBzJo1iz//+c8A3HrrrRxwwAEcdNBB/NVf/RUADz30EIcffjgHH3wwBx54II8++mgji25mw9SO+1PIn1wMT/1hYF/zla+B4/9tm5923nnncdZZZ3HWWWdxzTXXcP755zN37lwuu+wybr/9dvbYYw/Wrl0LwFVXXcXs2bM544wz6OjooFKpDOw6mJnVwTX3Otxzzz28+93vBuDMM8/k7rvvBuDII4/k7LPP5pvf/GZ3iL/uda/js5/9LJdffjlPPPEEI0du/RLDZmaDYcetuW9HDfvldtVVV/Gb3/yGH//4xxx22GHcd999vPvd72bmzJn8+Mc/5oQTTuAb3/gGxxxzTKOLambDjGvudTjiiCO4+eabAbjxxht5wxveAMBjjz3GzJkzueyyy5g0aRJLly5l8eLF7LXXXpx//vmcdNJJPPjgg40supkNUztuzb1BNm7cyOTJk7sfX3jhhVxxxRWcc845fO5zn2PSpElce+21AHzsYx/j0UcfJSKYNWsWBx10EJdffjk33HADzc3NvPKVr+QTn/hEo1bFzIaxIXnJX9s6b0ez4irsJX/NzKx/DnczswLa4cK9Uc1EReHtZ2awg4V7a2srq1evdkBtp4hg9erVtLa2NrooZtZgO9SvZSZPnsyyZctYtWpVo4syZLW2tm72ax8zG552qHBvbm5m+vTpjS6GmdmQt0M1y5iZ2cBwuJuZFZDD3cysgBzuZmYF5HA3Mysgh7uZWQE53M3MCqiucJd0nKRHJC2SdHEf06dKmi/pfkkPSjph4ItqZmb16jfcJZWBK4Hjgf2B0yXt32u2S4A5EXEIcBrwtYEuqJmZ1a+emvvhwKKIWBwRHcDNwEm95gngFdnwOODJgSuimZltq3rCfQ9gae7xsmxc3qXAeyQtA24DzuvrhSSdK2mBpAW+foyZ2eAZqBOqpwPXRcRk4ATgBkkveu2IuDoi2iKibdKkSQO0aDMz662ecF8OTMk9npyNy3sfMAcgIu4BWoGJA1FAMzPbdvWE+73ADEnTJbWQTpjO6zXPn4FZAJL2I4W7213MzBqk33CPiC7gw8DtwMOkX8U8JOkySSdms10EvF/SA8BNwNnhO26YmTVMXddzj4jbSCdK8+M+mRteCBw5sEUzM7Pt5X+ompkVkMPdzKyAHO5mZgXkcDczKyCHu5lZATnczcwKyOFuZlZADnczswJyuJuZFZDD3cysgBzuZmYF5HA3Mysgh7uZWQE53M3MCsjhbmZWQA53M7MCcribmRWQw93MrIAc7mZmBeRwNzMrIIe7mVkBOdzNzArI4W5mVkAOdzOzAnK4m5kVkMPdzKyAHO5mZgXkcDczKyCHu5lZATnczcwKqK5wl3ScpEckLZJ08RbmOUXSQkkPSfruwBbTzMy2RVN/M0gqA1cCbwKWAfdKmhcRC3PzzAA+DhwZEc9K2mWwCmxmZv2rp+Z+OLAoIhZHRAdwM3BSr3neD1wZEc8CRMTKgS2mmZlti3rCfQ9gae7xsmxc3quAV0n6paRfSzpuoApoZmbbrt9mmW14nRnAUcBk4BeSXhMRa/MzSToXOBdg6tSpA7RoMzPrrZ6a+3JgSu7x5Gxc3jJgXkR0RsTjwP+Swn4zEXF1RLRFRNukSZO2t8xmZtaPesL9XmCGpOmSWoDTgHm95plLqrUjaSKpmWbxAJbTzMy2Qb/hHhFdwIeB24GHgTkR8ZCkyySdmM12O7Ba0kJgPvCxiFg9WIU2M7OtU0Q0ZMFtbW2xYMGChizbzGyoknRfRLT1N5//oWpmVkAOdzOzAnK4m5kVkMPdzKyAHO5mZgXkcDczKyCHu5lZATnczcwKyOFuZlZADnczswJyuJuZFZDD3cysgBzuZmYF5HA3Mysgh7uZWQE53M3MCsjhbmZWQA53M7MCcribmRWQw93MrIAc7mZmBeRwNzMrIIe7mVkBOdzNzArI4W5mVkAOdzOzAnK4m5kVkMPdzKyAHO5mZgXkcDczKyCHu5lZAdUV7pKOk/SIpEWSLt7KfO+UFJLaBq6IZma2rfoNd0ll4ErgeGB/4HRJ+/cx31hgNvCbgS6kmZltm3pq7ocDiyJicUR0ADcDJ/Ux36eBy4H2ASyfmZlth3rCfQ9gae7xsmxcN0mHAlMi4sdbeyFJ50paIGnBqlWrtrmwZmZWn5d8QlVSCfgCcFF/80bE1RHRFhFtkyZNeqmLNjOzLagn3JcDU3KPJ2fjasYCBwB3SVoCvBaY55OqZmaNU0+43wvMkDRdUgtwGjCvNjEi1kXExIiYFhHTgF8DJ0bEgkEpsZmZ9avfcI+ILuDDwO3Aw8CciHhI0mWSThzsApqZ2bZrqmemiLgNuK3XuE9uYd6jXnqxzMzspfA/VM3MCsjhbmZWQA53M7MCcribmRWQw93MrIAc7mZmBeRwNzMrIIe7mVkBOdzNzArI4W5mVkAOdzOzAnK4m5kVkMPdzKyAHO5mZgXkcDczKyCHu5lZATnczcwKyOFuZlZADnczswJyuJuZFZDD3cysgBzuZmYF5HA3Mysgh7uZWQE53M3MCsjhbmZWQA53M7MCcribmRWQw93MrIAc7mZmBeRwNzMroLrCXdJxkh6RtEjSxX1Mv1DSQkkPSrpD0p4DX1QzM6tXv+EuqQxcCRwP7A+cLmn/XrPdD7RFxIHA94B/H+iCmplZ/eqpuR8OLIqIxRHRAdwMnJSfISLmR8TG7OGvgckDW0wzM9sW9YT7HsDS3ONl2bgteR/wk74mSDpX0gJJC1atWlV/Kc3MbJsM6AlVSe8B2oDP9TU9Iq6OiLaIaJs0adJALtrMzHKa6phnOTAl93hyNm4zko4F/g/wxojYNDDFMzOz7VFPzf1eYIak6ZJagNOAefkZJB0CfAM4MSJWDnwxc9qfg8d/MaiLMDMb6voN94joAj4M3A48DMyJiIckXSbpxGy2zwFjgFsl/V7SvC283Ev366/Bd06EjWsGbRFmZkNdPc0yRMRtwG29xn0yN3zsAJdry/Y+Bu76V1h8FxzwjpdtsWZmQ8nQ+4fq7odC6zh47M5Gl8TMbIc19MK93ATT3wiPzYeIRpfGzGyHNPTCHVLTzHPL4JlHG10SM7Md0hAN96NT300zZmZ9GprhvvM0GL83PHZHo0tiZrZDGprhDqlpZsnd0OX/S5mZ9TZ0w32fWdC5EZb+ptElMTPb4QzdcJ/2eig1ud3dzKwPQzfcR4yFKTMd7mZmfRi64Q7pVzMrHoDnn2l0SczMdihDPNyPSf3H5je2HGZmO5ihHe67HQwjd3bTjJlZL0M73Etl2OvoFO6+FIGZWbehHe6QmmY2PAUrH250SczMdhgFCHdfisDMrLehH+7jJsPEV/tSBGZmOUM/3CE1zTzxK+h8odElMTPbIRQn3Lva4c/3NLokZmY7hGKE+7Qjodzidnczs0wxwr1lNEx9rf/MZGaWKUa4Q2qaefqPsPi//Zt3Mxv2ihPu+5+Ubpx9/Ylw5eHwyy/DhpWNLpWZWUMUJ9zH7wUfeQhOvAJad4KffxK+sB/cfAY88lPo6mh0Cc3MXjZNjS7AgBoxFg7929StegR+dz08cDP86UfQPDpdA37vo9MlCya9GqRGl9jMbFAoGtQ+3dbWFgsWLBj8BXV1wKL/St3i+bBmcRo/dnfY6yjY/RDYaUr6M9S4Kalpx6FvZjsoSfdFRFt/8xWr5t6XphbY94TUATz7RAr5x+bD//4EHvju5vO3jE1hv/M0mLQv7LJf6k98FTS3vuzFNzPbHsUP99523hMOOzt11So8vwrWLYN1S7NuGaxdmmr4j/4Mql3peSqldv2Jr4ZX7A5jX9nTH7sbjNkVmlqh3Jxu/+fav5k10PAL97xSCcbumrrJh714elcHrHksXXFy1Z9Sf/UieOKX0L62n9duglJz+nPViLEwcqd07fnu/s4wagKM3gXGTMr6u8CoiVAe3m+Lmb10TpGtaWpJzTK77PfiaZ0vwPoVsP4peO7J9LPLrnaoVqDaCZXOnv6mDfDCs6l7ZlE2vAYqff2CRzB6UmoWGj8ddp7eMzxuctpp5OeFdJTQPCr9mctHDGaGw337NY9MzTTj99q+50dAx4a0U3h+FWx4umf4ueXp3MATv4IH5wB1nvRWKZ0zGFHrxqTAbxqZyts8KuuP7NkZtIyClmy+2nSV02uplHYWteFyc3Y0UutaUr9lTLpxipntMBzujSL1hPCEvbc8X9emdA7g2cdT6Ec1jc//yimq0LkRNq3Pdc+lfucLsHF16ne2p/k6X4CuAb6CZsvY9Euj1ldk/XGA0nI62zfv1+av7XxaxqTt0NS6hSOPbFvVXjffSVDpSudGqp2pX+lKO5um1rSzahqR7eBa0w5JpfSayh35QDoHU3uNald2FFZJO7DmUen5TSPT477KGZHei9pO0ayB6gp3SccBXwbKwLci4t96TR8BXA8cBqwGTo2IJQNb1GGqaQRM3Cd1A6ma7RA6nk9HELXhzo1ZSGVB1d1VsuDs1eRU6UjNTu3rsm5t6j+3PCt/Fqqt43rCEdIyN62H9udSs9amrAx9hmY1zVs7ud1oKqX1kLIdQFfaPrUdL2Q7g1HpyKg5O0Iqj+jZjtVKNlwBlM67jN2t5wT92Fem8zBd7WmbvrA211+Xxne/D7mdW7ml55xOvmsZA+TeV7J+tZK9j5tSRaLSkfU70zmpcksqd/eRWktqrmzKdpRNrVk3Im2XSkf2OenIus60nPwOtrvfmpWnsvnOtPtxV27dajvvSlZ2etYhIr0X3UeWLT1Hl6Wmzbd1bTiqafkto3uOWlvGpHWLSNugVhHqfCENEz1lbx7VU3mo56i19podG1LXulM6/zaI+g13SWXgSuBNwDLgXknzImJhbrb3Ac9GxD6STgMuB04djALbACmVUs15xBhg10aXpn8R6QvWvq4n4NrXpWmlpnQSutTcM1yt5o4Wsq7zhZ7zHLVQqAVe7XVK5Z5QKDX1BFbnxl5HIO3peaVy6pTrV7uy+TdCx0bofD71Kx1QaumZt/b6EfD8SlhydzqHU+3c8nYoNWc7ylE965wvb6UDVi5M22jTc4P6lhRSqamnQlP3c/I7lJae4VI5ve+1ClRUep7z1i9C23sHvvw59dTcDwcWRcRiAEk3AycB+XA/Cbg0G/4e8FVJikb9Q8qKR+qpZb1i90aXZvBUq+lk+/oV6RxM88hUy2sdl2p6zaPqb/KpdKaQf+FZ6FhPaorq61xKrUY+YvN+tbJ5Dbx7uCPbYW7Kde0pvGqvVWrqGZaynWuv5rmuTWlaqSnb4WU71+7zO019dGW6m9S6m9dINflqZ66snT1HEb13vqVyVqZNWfBmR6wdG1IYl8o9R175c1XQU0noat98h9+9zE2bL7t59ObNjy1ZhWry4YPy8cmrJ9z3AJbmHi8DZm5pnojokrQOmAA8k59J0rnAuQBTp07dziKbFVipBKMnpu6lKjen5p4xk7azLOXUTGFD0st64bCIuDoi2iKibdKk7fzAmZlZv+oJ9+XAlNzjydm4PueR1ASMI51YNTOzBqgn3O8FZkiaLqkFOA2Y12ueecBZ2fDfAHe6vd3MrHH6bXPP2tA/DNxO+inkNRHxkKTLgAURMQ/4NnCDpEXAGtIOwMzMGqSu37lHxG3Abb3GfTI33A7tgAgzAAAFC0lEQVS8a2CLZmZm26s4d2IyM7NuDnczswJyuJuZFVDDbrMnaRXwxHY+fSK9/iA1TAzX9Ybhu+5e7+GlnvXeMyL6/aNQw8L9pZC0oJ57CBbNcF1vGL7r7vUeXgZyvd0sY2ZWQA53M7MCGqrhfnWjC9Agw3W9Yfiuu9d7eBmw9R6Sbe5mZrZ1Q7XmbmZmW+FwNzMroCEX7pKOk/SIpEWSLm50eQaLpGskrZT0x9y48ZJ+LunRrL9zI8s4GCRNkTRf0kJJD0manY0v9LpLapX0W0kPZOv9z9n46ZJ+k33eb8muzFo4ksqS7pf0o+xx4ddb0hJJf5D0e0kLsnED9jkfUuGeu5/r8cD+wOmS9m9sqQbNdcBxvcZdDNwRETOAO7LHRdMFXBQR+wOvBT6UvcdFX/dNwDERcRBwMHCcpNeS7kf8xYjYB3iWdL/iIpoNPJx7PFzW++iIODj32/YB+5wPqXAndz/XiOgAavdzLZyI+AXp8sl5JwHfyYa/A7z9ZS3UyyAiVkTE77Lh9aQv/B4UfN0j2ZA9bM66AI4h3ZcYCrjeAJImA28BvpU9FsNgvbdgwD7nQy3c+7qf6x4NKksj7BoRK7Lhp4BdG1mYwSZpGnAI8BuGwbpnTRO/B1YCPwceA9ZGRFc2S1E/718C/gGoZo8nMDzWO4CfSbovu780DODnvK7ruduOJyJCUmF/xyppDPB94IKIeC5V5pKirntEVICDJe0E/BDYt8FFGnSS3gqsjIj7JB3V6PK8zF4fEcsl7QL8XNKf8hNf6ud8qNXc67mfa5E9LWk3gKy/ssHlGRSSmknBfmNE/CAbPSzWHSAi1gLzgdcBO2X3JYZift6PBE6UtITUzHoM8GWKv95ExPKsv5K0Mz+cAfycD7Vwr+d+rkWWv1ftWcB/NrAsgyJrb/028HBEfCE3qdDrLmlSVmNH0kjgTaTzDfNJ9yWGAq53RHw8IiZHxDTS9/nOiDiDgq+3pNGSxtaGgb8G/sgAfs6H3D9UJZ1AaqOr3c/1XxpcpEEh6SbgKNIlQJ8GPgXMBeYAU0mXSz4lInqfdB3SJL0e+B/gD/S0wX6C1O5e2HWXdCDpBFqZVOmaExGXSdqLVKMdD9wPvCciNjWupIMna5b5aES8tejrna3fD7OHTcB3I+JfJE1ggD7nQy7czcysf0OtWcbMzOrgcDczKyCHu5lZATnczcwKyOFuZlZADncrLEmV7Ip7tW7ALjYmaVr+ip1mOxpffsCK7IWIOLjRhTBrBNfcbdjJrqP979m1tH8raZ9s/DRJd0p6UNIdkqZm43eV9MPsWusPSDoie6mypG9m11//WfbPUrMdgsPdimxkr2aZU3PT1kXEa4Cvkv7xDHAF8J2IOBC4EfhKNv4rwH9n11o/FHgoGz8DuDIi/gJYC7xzkNfHrG7+h6oVlqQNETGmj/FLSDfGWJxdpOypiJgg6Rlgt4jozMaviIiJklYBk/N/f88uR/zz7KYKSPpHoDkiPjP4a2bWP9fcbbiKLQxvi/y1Tir4HJbtQBzuNlydmuvfkw3/inRlQoAzSBcwg3S7sw9C9w01xr1chTTbXq5pWJGNzO5sVPPTiKj9HHJnSQ+Sat+nZ+POA66V9DFgFXBONn42cLWk95Fq6B8EVmC2A3Obuw07WZt7W0Q80+iymA0WN8uYmRWQa+5mZgXkmruZWQE53M3MCsjhbmZWQA53M7MCcribmRXQ/wfdqfLWSk2j6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves(vanilla_clf_with_bn._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9470615671641791, 0.9798274253731343, 0.9838752665245203, 0.9864738805970149, 0.9869569562899787, 0.9888392857142857, 0.9900053304904051, 0.9896388592750534, 0.9905883528784648, 0.9918876599147122, 0.9924373667377399, 0.9927372068230277, 0.9932702558635395, 0.9933535447761194, 0.9938033049040512, 0.9935367803837953, 0.9946528518123667, 0.9948694029850746, 0.9946861673773987, 0.9947861140724946, 0.9949693496801706, 0.9955523720682303, 0.9955357142857143, 0.9960021321961621, 0.99596881663113, 0.9956190031982942, 0.9959021855010661, 0.995985474413646, 0.996068763326226, 0.9964518923240938, 0.9974680170575693, 0.9966184701492538, 0.9966517857142857, 0.9972847814498934, 0.9969016524520256, 0.9966851012793176, 0.9969016524520256, 0.9972847814498934, 0.9969516257995735, 0.9973514125799574, 0.9975179904051172, 0.9969849413646056, 0.9970349147121536, 0.9970182569296375, 0.9970682302771855, 0.9974846748400853, 0.9972348081023454, 0.9978844616204691, 0.9977012260127932, 0.9973014392324094]\n",
      "[0.17879931617583802, 0.06510292157244835, 0.05305530907197008, 0.04465456768425543, 0.04095516235196292, 0.035686698168821966, 0.03246649506408523, 0.03187506042444693, 0.02969339288456409, 0.02688482559860936, 0.022680633018530016, 0.022633540268584308, 0.02094882543954347, 0.019762927854085153, 0.01833346364798763, 0.018111565296274067, 0.017449623491587258, 0.015518361826237144, 0.01659209574028519, 0.015044793289632343, 0.015067296203854842, 0.013101909521140351, 0.013663651822138575, 0.012587211846655953, 0.012437350869677446, 0.012962119922209194, 0.011835834141658085, 0.01222078301451742, 0.010899786284984723, 0.011309559853877306, 0.008159592543496068, 0.010212633250490216, 0.010795954370504813, 0.008579049872838631, 0.008781245785226339, 0.009630499544480482, 0.00887376679496508, 0.00794204235541883, 0.008634129374802521, 0.0075175914053053315, 0.007932562196244627, 0.008461461609778571, 0.008624332326420358, 0.007940978866067034, 0.008339568415457117, 0.006935876334889798, 0.008174488858250565, 0.007041013497223066, 0.006299754133544066, 0.0078081758663694715]\n"
     ]
    }
   ],
   "source": [
    "print(vanilla_clf_with_bn._model.history.history['acc'])\n",
    "print(vanilla_clf_with_bn._model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN MODEL WITHOUT BATCHNORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.2383 - acc: 0.9272\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0891 - acc: 0.9730\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0701 - acc: 0.9786\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0563 - acc: 0.9828\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0531 - acc: 0.9835\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0448 - acc: 0.9857\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0440 - acc: 0.9863\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0400 - acc: 0.9869\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0363 - acc: 0.9878\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0355 - acc: 0.9888\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0314 - acc: 0.9897\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0295 - acc: 0.9906\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0280 - acc: 0.9908\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0265 - acc: 0.9915\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0245 - acc: 0.9921\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0239 - acc: 0.9921\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0236 - acc: 0.9925\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0225 - acc: 0.9926\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0214 - acc: 0.9928\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0213 - acc: 0.9932\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0195 - acc: 0.9938\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0197 - acc: 0.9938\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0198 - acc: 0.9933\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0182 - acc: 0.9943\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0170 - acc: 0.9942\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0169 - acc: 0.9946\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0166 - acc: 0.9943\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0165 - acc: 0.9943\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0155 - acc: 0.9949\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0163 - acc: 0.9945\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0157 - acc: 0.9948\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0139 - acc: 0.9950\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0140 - acc: 0.9952\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0130 - acc: 0.9958\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0124 - acc: 0.9956\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0114 - acc: 0.9963\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0131 - acc: 0.9960\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0114 - acc: 0.9962\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf = get_vanilla_model(x_train, y_train)\n",
    "save_clf(vanilla_clf, '/home/surthi/models/mnist/', 'vanilla_clf.h5', 'vanilla_clf_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(clf, x_train, x_test):\n",
    "    from art.attacks import DeepFool\n",
    "    deep_adv_crafter = DeepFool(clf)\n",
    "    x_train_deepfool_adv = deep_adv_crafter.generate(x_train)\n",
    "    x_test_deepfool_adv = deep_adv_crafter.generate(x_test)\n",
    "    return x_train_deepfool_adv, x_test_deepfool_adv\n",
    "\n",
    "def carlinil2(clf, x_train, x_test):\n",
    "    from art.attacks import CarliniL2Method\n",
    "    cl2_adv_crafter = CarliniL2Method(classifier=clf, targeted=False, max_iter=5)\n",
    "    x_train_cl2_adv = cl2_adv_crafter.generate(x_train)\n",
    "    x_test_cl2_adv = cl2_adv_crafter.generate(x_test)\n",
    "    return x_train_cl2_adv, x_test_cl2_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 17.06 14.40%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1706, 0.144)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cl2_adv, x_test_cl2_adv = carlinil2(vanilla_clf, x_train[:5000], x_test[:1000])\n",
    "evaluate(vanilla_clf, x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump((x_train_cl2_adv, x_test_cl2_adv), 'mnist-cl2-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 11.34 11.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1134, 0.112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_deepfool_adv, x_test_deepfool_adv = deepfool(vanilla_clf, x_train[:5000], x_test[:1000])\n",
    "evaluate(vanilla_clf, x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump((x_train_deepfool_adv, x_test_deepfool_adv), 'mnist-deepfool-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 28.83 30.52%\n",
      "/home/surthi/models\n"
     ]
    }
   ],
   "source": [
    "def fgsm(clf, x_train, x_test, epsilon=0.1):\n",
    "    from art.attacks.fast_gradient import FastGradientMethod\n",
    "    epsilon = .1  # Maximum perturbation\n",
    "#     fgsm_adv_crafter = FastGradientMethod(clf, eps=epsilon)\n",
    "#     fgsm_adv_crafter = FastGradientMethod(clf, eps=0.4, batch_size=2)\n",
    "    fgsm_adv_crafter = FastGradientMethod(clf, eps=0.4, eps_step=0.01, batch_size=2)\n",
    "    x_test_fgsm_adv = fgsm_adv_crafter.generate(x=x_test)\n",
    "    x_train_fgsm_adv = fgsm_adv_crafter.generate(x=x_train)\n",
    "    return x_train_fgsm_adv, x_test_fgsm_adv\n",
    "\n",
    "def ifgsm(clf, x_train, x_test, epsilon=0.1, max_iter=10):\n",
    "    from art.attacks.iterative_method import BasicIterativeMethod\n",
    "    ifgsm_adv_crafter = BasicIterativeMethod(clf, eps=epsilon, eps_step=0.1, max_iter=max_iter)\n",
    "    x_test_ifgsm_adv = ifgsm_adv_crafter.generate(x=x_test)\n",
    "    x_train_ifgsm_adv = ifgsm_adv_crafter.generate(x=x_train)\n",
    "    return x_train_ifgsm_adv, x_test_ifgsm_adv\n",
    "\n",
    "x_train_fgsm_adv, x_test_fgsm_adv = fgsm(vanilla_clf, x_train, x_test, epsilon=1.0)\n",
    "evaluate(vanilla_clf, x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "pickle_dump((x_train_fgsm_adv, x_test_fgsm_adv), 'mnist-fgsm-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.iterative_method import BasicIterativeMethod\n",
    "ifgsm_adv_crafter = BasicIterativeMethod(vanilla_clf, eps=0.1, eps_step=0.1, max_iter=20)\n",
    "x_test_ifgsm_adv = ifgsm_adv_crafter.generate(x=x_test)\n",
    "x_train_ifgsm_adv = ifgsm_adv_crafter.generate(x=x_train)\n",
    "evaluate(vanilla_clf, x_train_ifgsm_adv, y_train, x_test_ifgsm_adv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n"
     ]
    }
   ],
   "source": [
    "x_train_ifgsm_adv, x_test_ifgsm_adv = ifgsm(vanilla_clf, x_train, x_test)\n",
    "evaluate(vanilla_clf, x_train_ifgsm_adv, y_train, x_test_ifgsm_adv, y_test)\n",
    "pickle_dump((x_train_ifgsm_adv, x_test_ifgsm_adv), 'mnist-ifgsm-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surthi/models\n"
     ]
    }
   ],
   "source": [
    "pickle_dump((x_train_ifgsm_adv, x_test_ifgsm_adv), 'mnist-ifgsm-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cl2_adv, x_test_cl2_adv = pickle_load('/home/surthi/models/mnist-cl2-data.pkl')\n",
    "x_train_deepfool_adv, x_test_deepfool_adv = pickle_load('/home/surthi/models/mnist-deepfool-data.pkl')\n",
    "x_train_fgsm_adv, x_test_fgsm_adv = pickle_load('/home/surthi/models/mnist-fgsm-data.pkl')\n",
    "x_train_ifgsm_adv1, x_test_ifgsm_adv1 = pickle_load('/home/surthi/models/mnist-ifgsm-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surthi/models\n"
     ]
    }
   ],
   "source": [
    "pickle_dump([x_train[5], x_train_ifgsm_adv1[5],x_train_fgsm_adv[5], x_train_deepfool_adv[5], x_train_cl2_adv[5]], \"mnist-5images.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Acc of Models against adversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 99.98 99.40%\n",
      "\n",
      "Training and Test accuracies: 28.83 30.52%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "\n",
      "Training and Test accuracies: 11.34 11.20%\n",
      "\n",
      "Training and Test accuracies: 17.06 14.40%\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = evaluate(vanilla_clf, x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc, fgsm_test_acc = evaluate(vanilla_clf, x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc, ifgsm_test_acc = evaluate(vanilla_clf, x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc, df_test_acc = evaluate(vanilla_clf, x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc, cl2_test_acc = evaluate(vanilla_clf, x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n",
      "\n",
      "Training and Test accuracies: 24.70 24.66%\n",
      "\n",
      "Training and Test accuracies: 2.05 2.43%\n",
      "\n",
      "Training and Test accuracies: 88.98 91.00%\n",
      "\n",
      "Training and Test accuracies: 70.30 68.70%\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = evaluate(vanilla_clf_with_bn, x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc, fgsm_test_acc = evaluate(vanilla_clf_with_bn, x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc, ifgsm_test_acc = evaluate(vanilla_clf_with_bn, x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc, df_test_acc = evaluate(vanilla_clf_with_bn, x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc, cl2_test_acc = evaluate(vanilla_clf_with_bn, x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_training_1(clf, x_train, y_train, x_train_adv, x_test_adv, x_test, y_test, epochs=5, batch_size=128):\n",
    "    print(\"Before training:\")\n",
    "    evaluate(clf, x_train, y_train, x_test, y_test)    \n",
    "    evaluate(clf, x_train_adv, y_train, x_test_adv, y_test)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        clf.fit(x_train_adv, y_train, nb_epochs=1, batch_size=128)\n",
    "        clf.fit(x_train, y_train, nb_epochs=1, batch_size=128)\n",
    "    \n",
    "    print(\"After training:\")\n",
    "    evaluate(clf, x_train, y_train, x_test, y_test)    \n",
    "    evaluate(clf, x_train_adv, y_train, x_test_adv, y_test)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.40%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 16.1141 - acc: 2.4987e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1159 - acc: 1.3326e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1146 - acc: 2.1655e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1157 - acc: 1.4992e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0142 - acc: 0.9953\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1130 - acc: 3.1650e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0139 - acc: 0.9956\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.34%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.34%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1154 - acc: 1.6658e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1141 - acc: 2.4987e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0137 - acc: 0.9958\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1146 - acc: 2.1655e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0138 - acc: 0.9955\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1141 - acc: 2.4987e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0140 - acc: 0.9953\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1130 - acc: 3.1650e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0125 - acc: 0.9959\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.32%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.32%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.1159 - acc: 1.3326e-04\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 16.0707 - acc: 0.0029\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0659 - acc: 0.9886\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.4199 - acc: 0.1053\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0669 - acc: 0.9881\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3230 - acc: 0.1113\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0182 - acc: 0.9942\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2925 - acc: 0.1132\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0130 - acc: 0.9956\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3144 - acc: 0.1119\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0124 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3181 - acc: 0.1117\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3058 - acc: 0.1124\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0142 - acc: 0.9954\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3117 - acc: 0.1121\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3418 - acc: 0.1102\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0142 - acc: 0.9954\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.31%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.31%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3162 - acc: 0.1118\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0127 - acc: 0.9958\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3141 - acc: 0.1119\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0132 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3592 - acc: 0.1091\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0157 - acc: 0.9954\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2803 - acc: 0.1140\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2988 - acc: 0.1129\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0125 - acc: 0.9961\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.23%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.23%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3350 - acc: 0.1106\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3106 - acc: 0.1121\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2841 - acc: 0.1138\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2988 - acc: 0.1129\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2913 - acc: 0.1133\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0120 - acc: 0.9962\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3367 - acc: 0.1105\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3305 - acc: 0.1109\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3138 - acc: 0.1119\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0131 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2894 - acc: 0.1135\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0111 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3106 - acc: 0.1121\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0125 - acc: 0.9961\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.25%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.25%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2881 - acc: 0.1135\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0112 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2768 - acc: 0.1142\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3007 - acc: 0.1128\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3139 - acc: 0.1119\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0108 - acc: 0.9962\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3071 - acc: 0.1124\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0107 - acc: 0.9966\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2958 - acc: 0.1131\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3077 - acc: 0.1123\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3318 - acc: 0.1108\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3455 - acc: 0.1100\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2870 - acc: 0.1136\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0106 - acc: 0.9965\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.31%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf, '/home/surthi/models/mnist/', 'vanilla_clf_adv.h5', 'vanilla_clf_model_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.31%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3275 - acc: 0.1111\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2803 - acc: 0.1140\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3246 - acc: 0.1113\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0118 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3154 - acc: 0.1118\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3112 - acc: 0.1121\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0123 - acc: 0.9963\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2929 - acc: 0.1132\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0106 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2996 - acc: 0.1128\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3181 - acc: 0.1117\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3015 - acc: 0.1127\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0119 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3235 - acc: 0.1113\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0096 - acc: 0.9970\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.38%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.38%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3302 - acc: 0.1109\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3004 - acc: 0.1128\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0105 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3098 - acc: 0.1122\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3514 - acc: 0.1096\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3345 - acc: 0.1107\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0076 - acc: 0.9973\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.44%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.44%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2848 - acc: 0.1137\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3050 - acc: 0.1125\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3447 - acc: 0.1100\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2797 - acc: 0.11410s - loss: 14.2769 - acc\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3001 - acc: 0.1128\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0105 - acc: 0.9968\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.33%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.33%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2980 - acc: 0.1129\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0112 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3095 - acc: 0.1122\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0093 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3098 - acc: 0.1122\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3205 - acc: 0.1115\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2996 - acc: 0.1128\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0118 - acc: 0.9966\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf, '/home/surthi/models/mnist/', 'vanilla_clf_adv.h5', 'vanilla_clf_model_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3077 - acc: 0.1123\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0100 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2953 - acc: 0.1131\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2795 - acc: 0.1141\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0089 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3136 - acc: 0.1120\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0104 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3165 - acc: 0.1118\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0112 - acc: 0.9966\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3235 - acc: 0.1113\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3385 - acc: 0.1104\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3224 - acc: 0.1114\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3369 - acc: 0.1105\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3243 - acc: 0.1113\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0080 - acc: 0.9976\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.41%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.41%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3162 - acc: 0.1118\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2855 - acc: 0.1137\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2921 - acc: 0.1133\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3189 - acc: 0.1116\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0091 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2660 - acc: 0.1149\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0104 - acc: 0.9971\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.37%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.37%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3047 - acc: 0.1125\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2870 - acc: 0.1136\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2593 - acc: 0.1153\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3254 - acc: 0.1112\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.3148 - acc: 0.1119\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0099 - acc: 0.9969\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.41%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.41%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2601 - acc: 0.1153\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0086 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2950 - acc: 0.1131\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2977 - acc: 0.1129\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2905 - acc: 0.1134\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 14.2905 - acc: 0.1134\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0097 - acc: 0.9972\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1 = adv_training_1(vanilla_clf, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf, '/home/surthi/models/mnist/', 'vanilla_clf_adv.h5', 'vanilla_clf_model_adv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BN Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n",
      "\n",
      "Training and Test accuracies: 2.05 2.43%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.5868 - acc: 0.8998\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0727 - acc: 0.9781\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0863 - acc: 0.9738\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0316 - acc: 0.9895\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0552 - acc: 0.9830\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0254 - acc: 0.9919\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0434 - acc: 0.9865\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0248 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0366 - acc: 0.9889\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0224 - acc: 0.9925\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.91 99.24%\n",
      "\n",
      "Training and Test accuracies: 54.52 55.45%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.91 99.24%\n",
      "\n",
      "Training and Test accuracies: 54.52 55.45%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0280 - acc: 0.9919\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0221 - acc: 0.9934\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0168 - acc: 0.9945\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0207 - acc: 0.9938\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0144 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0200 - acc: 0.9938\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0170 - acc: 0.9943\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0152 - acc: 0.9948\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.96 99.27%\n",
      "\n",
      "Training and Test accuracies: 66.60 66.97%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.96 99.27%\n",
      "\n",
      "Training and Test accuracies: 66.60 66.97%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0132 - acc: 0.9958\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0141 - acc: 0.9953\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0127 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0142 - acc: 0.9953\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0138 - acc: 0.9955\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0133 - acc: 0.9956\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0137 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0149 - acc: 0.9951\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.24%\n",
      "\n",
      "Training and Test accuracies: 66.02 66.33%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.24%\n",
      "\n",
      "Training and Test accuracies: 66.02 66.33%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0121 - acc: 0.9956\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0103 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0114 - acc: 0.9962\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0115 - acc: 0.9960\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.31%\n",
      "\n",
      "Training and Test accuracies: 78.30 78.01%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.31%\n",
      "\n",
      "Training and Test accuracies: 78.30 78.01%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0097 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0129 - acc: 0.9954\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0109 - acc: 0.9963\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0070 - acc: 0.9981\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0104 - acc: 0.9964\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.28%\n",
      "\n",
      "Training and Test accuracies: 72.16 72.29%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,219,658\n",
      "Trainable params: 1,219,146\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_with_bn._model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,218,634\n",
      "Trainable params: 1,218,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf._model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf_with_bn, '/home/surthi/models/mnist/', 'vanilla_clf_bn_adv.h5', 'vanilla_clf_bn_model_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.28%\n",
      "\n",
      "Training and Test accuracies: 72.16 72.29%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0121 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0080 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0096 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0055 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0098 - acc: 0.9966\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0085 - acc: 0.9972\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.31%\n",
      "\n",
      "Training and Test accuracies: 73.23 73.34%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.31%\n",
      "\n",
      "Training and Test accuracies: 73.23 73.34%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0049 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0104 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0073 - acc: 0.9981\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0097 - acc: 0.9967\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.24%\n",
      "\n",
      "Training and Test accuracies: 70.29 70.45%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.24%\n",
      "\n",
      "Training and Test accuracies: 70.29 70.45%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0070 - acc: 0.9981\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0099 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0088 - acc: 0.9969\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.24%\n",
      "\n",
      "Training and Test accuracies: 75.56 75.40%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.98 99.24%\n",
      "\n",
      "Training and Test accuracies: 75.56 75.40%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0055 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0079 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0063 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0079 - acc: 0.9972\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.37%\n",
      "\n",
      "Training and Test accuracies: 68.46 68.46%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.37%\n",
      "\n",
      "Training and Test accuracies: 68.46 68.46%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0081 - acc: 0.9971\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.33%\n",
      "\n",
      "Training and Test accuracies: 74.12 74.16%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf_with_bn, '/home/surthi/models/mnist/', 'vanilla_clf_bn_adv.h5', 'vanilla_clf_bn_model_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.33%\n",
      "\n",
      "Training and Test accuracies: 74.12 74.16%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0050 - acc: 0.9986\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0061 - acc: 0.9983\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0073 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0083 - acc: 0.9972\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.22%\n",
      "\n",
      "Training and Test accuracies: 72.43 72.80%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.97 99.22%\n",
      "\n",
      "Training and Test accuracies: 72.43 72.80%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0042 - acc: 0.9989\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0072 - acc: 0.9977\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.33%\n",
      "\n",
      "Training and Test accuracies: 69.83 69.83%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.33%\n",
      "\n",
      "Training and Test accuracies: 69.83 69.83%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0063 - acc: 0.9986\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0059 - acc: 0.9986\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0074 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0064 - acc: 0.9979\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 68.67 68.61%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 68.67 68.61%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0072 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0050 - acc: 0.9990\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0046 - acc: 0.9991\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0068 - acc: 0.9975\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0072 - acc: 0.9977\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.31%\n",
      "\n",
      "Training and Test accuracies: 71.12 71.31%\n",
      "Before training:\n",
      "\n",
      "Training and Test accuracies: 100.00 99.31%\n",
      "\n",
      "Training and Test accuracies: 71.12 71.31%\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0042 - acc: 0.9989\n",
      "Epoch 1/1\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0068 - acc: 0.9977\n",
      "After training:\n",
      "\n",
      "Training and Test accuracies: 99.99 99.30%\n",
      "\n",
      "Training and Test accuracies: 76.78 76.39%\n"
     ]
    }
   ],
   "source": [
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)\n",
    "vanilla_clf_adv_trained_1bn = adv_training_1(vanilla_clf_with_bn, x_train, y_train, x_train_ifgsm_adv, x_test_ifgsm_adv, x_test, y_test, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf(vanilla_clf_with_bn, '/home/surthi/models/mnist/', 'vanilla_clf_bn_adv.h5', 'vanilla_clf_bn_model_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vanilla_clf_with_bn_adv = load_clf('/home/surthi/models/mnist/', 'vanilla_clf_bn_adv.h5', 'vanilla_clf_bn_model_adv.h5')\n",
    "loaded_vanilla_clf_adv = load_clf('/home/surthi/models/mnist/', 'vanilla_clf_adv.h5', 'vanilla_clf_model_adv.h5')\n",
    "loaded_vanilla_clf = load_clf('/home/surthi/models/mnist/', 'vanilla_clf.h5', 'vanilla_clf_model.h5')\n",
    "loaded_vanilla_clf_with_bn = load_clf('/home/surthi/models/mnist/', 'vanilla_clf_with_bn.h5', 'vanilla_clf_with_bn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Detector = Ensemble of MNIST-CNN-WITHOUT-BatchNorm and MNIST-BIM-ADV-TRAINED MODEL\n",
    "## If both the models agree, then its clean image else its an adversarial. It detected other black-box attacks well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.99      1.00     10000\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       1.00      0.99      1.00     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "preds1 = np.argmax(loaded_vanilla_clf[0].predict(x_test), axis=1)\n",
    "preds2 = np.argmax(loaded_vanilla_clf_with_bn_adv[0].predict(x_test), axis=1)\n",
    "clean_adv_detection = preds1 == preds2\n",
    "np.ones(clean_adv_detection.shape, dtype=int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.ones(clean_adv_detection.shape, dtype=int), clean_adv_detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00     10000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds1 = np.argmax(loaded_vanilla_clf[0].predict(x_test_ifgsm_adv1), axis=1)\n",
    "preds2 = np.argmax(loaded_vanilla_clf_with_bn_adv[0].predict(x_test_ifgsm_adv1), axis=1)\n",
    "clean_adv_detection = preds1 != preds2\n",
    "np.ones(clean_adv_detection.shape, dtype=int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.ones(clean_adv_detection.shape, dtype=int), clean_adv_detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.86      0.93     10000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.50      0.43      0.46     10000\n",
      "weighted avg       1.00      0.86      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds1 = np.argmax(loaded_vanilla_clf[0].predict(x_test_fgsm_adv), axis=1)\n",
    "preds2 = np.argmax(loaded_vanilla_clf_with_bn_adv[0].predict(x_test_fgsm_adv), axis=1)\n",
    "clean_adv_detection = preds1 != preds2\n",
    "np.ones(clean_adv_detection.shape, dtype=int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.ones(clean_adv_detection.shape, dtype=int), clean_adv_detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.77      0.87      1000\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.50      0.38      0.43      1000\n",
      "weighted avg       1.00      0.77      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds1 = np.argmax(loaded_vanilla_clf[0].predict(x_test_cl2_adv), axis=1)\n",
    "preds2 = np.argmax(loaded_vanilla_clf_with_bn_adv[0].predict(x_test_cl2_adv), axis=1)\n",
    "clean_adv_detection = preds1 != preds2\n",
    "np.ones(clean_adv_detection.shape, dtype=int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.ones(clean_adv_detection.shape, dtype=int), clean_adv_detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.88      0.93      1000\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.50      0.44      0.47      1000\n",
      "weighted avg       1.00      0.88      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds1 = np.argmax(loaded_vanilla_clf[0].predict(x_test_deepfool_adv), axis=1)\n",
    "preds2 = np.argmax(loaded_vanilla_clf_with_bn_adv[0].predict(x_test_deepfool_adv), axis=1)\n",
    "clean_adv_detection = preds1 != preds2\n",
    "np.ones(clean_adv_detection.shape, dtype=int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.ones(clean_adv_detection.shape, dtype=int), clean_adv_detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "N = 3000\n",
    "bim_perturbation = np.mean(la.norm((x_train[:N]-x_test_ifgsm_adv1[:N]).reshape(N, -1), 2, axis=1))\n",
    "fgsm_perturbation = np.mean(la.norm((x_train[:N]-x_train_fgsm_adv[:N]).reshape(N, -1), 2, axis=1))\n",
    "cl2_perturbation = np.mean(la.norm((x_train[:N]-x_train_cl2_adv[:N]).reshape(N, -1), 2, axis=1))\n",
    "df_perturbation = np.mean(la.norm((x_train[:N]-x_train_deepfool_adv[:N]).reshape(N, -1), 2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.01417679975898 8.968844231824544 2.6234788295148164 1.452307249586318\n"
     ]
    }
   ],
   "source": [
    "print(bim_perturbation, fgsm_perturbation, cl2_perturbation, df_perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_perturbations = (1.452307249586318, 2.6234788295148164, 8.968844231824544, 19.01417679975898)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,2))\n",
    "y_pos = np.arange(len(avg_perturbations))\n",
    "plt.bar(y_pos, avg_perturbations, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, ['DeepFool', 'CWL2', 'FGSM', 'BIM'])\n",
    "plt.title('L2 Norm of Perturbations for different attacks')\n",
    "# plt.xlabel('Attack Types')\n",
    "plt.ylabel('Perturbation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 99.98 99.40%\n",
      "\n",
      "Training and Test accuracies: 28.83 30.52%\n",
      "\n",
      "Training and Test accuracies: 0.02 0.51%\n",
      "\n",
      "Training and Test accuracies: 11.34 11.20%\n",
      "\n",
      "Training and Test accuracies: 17.06 14.40%\n",
      "\n",
      "Training and Test accuracies: 100.00 99.32%\n",
      "\n",
      "Training and Test accuracies: 24.70 24.66%\n",
      "\n",
      "Training and Test accuracies: 2.05 2.43%\n",
      "\n",
      "Training and Test accuracies: 88.98 91.00%\n",
      "\n",
      "Training and Test accuracies: 70.30 68.70%\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = evaluate(loaded_vanilla_clf[0], x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc, fgsm_test_acc = evaluate(loaded_vanilla_clf[0], x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc, ifgsm_test_acc = evaluate(loaded_vanilla_clf[0], x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc, df_test_acc = evaluate(loaded_vanilla_clf[0], x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc, cl2_test_acc = evaluate(loaded_vanilla_clf[0], x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])\n",
    "\n",
    "train_acc_bn, test_acc_bn = evaluate(loaded_vanilla_clf_with_bn[0], x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc_bn, fgsm_test_acc_bn = evaluate(loaded_vanilla_clf_with_bn[0], x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc_bn, ifgsm_test_acc_bn = evaluate(loaded_vanilla_clf_with_bn[0], x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc_bn, df_test_acc_bn = evaluate(loaded_vanilla_clf_with_bn[0], x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc_bn, cl2_test_acc_bn = evaluate(loaded_vanilla_clf_with_bn[0], x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 99.99 99.30%\n",
      "\n",
      "Training and Test accuracies: 34.24 34.33%\n",
      "\n",
      "Training and Test accuracies: 76.78 76.39%\n",
      "\n",
      "Training and Test accuracies: 97.10 97.80%\n",
      "\n",
      "Training and Test accuracies: 89.60 89.40%\n"
     ]
    }
   ],
   "source": [
    "train_acc_bn_adv, test_acc_bn_adv = evaluate(loaded_vanilla_clf_with_bn_adv[0], x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc_bn_adv, fgsm_test_acc_bn_adv = evaluate(loaded_vanilla_clf_with_bn_adv[0], x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc_bn_adv, ifgsm_test_acc_bn_adv = evaluate(loaded_vanilla_clf_with_bn_adv[0], x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc_bn_adv, df_test_acc_bn_adv = evaluate(loaded_vanilla_clf_with_bn_adv[0], x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc_bn_adv, cl2_test_acc_bn_adv = evaluate(loaded_vanilla_clf_with_bn_adv[0], x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Test accuracies: 100.00 99.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "\n",
      "Training and Test accuracies: 11.24 11.35%\n",
      "\n",
      "Training and Test accuracies: 72.44 75.00%\n",
      "\n",
      "Training and Test accuracies: 69.62 68.40%\n"
     ]
    }
   ],
   "source": [
    "train_acc_adv, test_acc_adv = evaluate(loaded_vanilla_clf_adv[0], x_train, y_train, x_test, y_test)\n",
    "fgsm_train_acc_adv, fgsm_test_acc_adv = evaluate(loaded_vanilla_clf_adv[0], x_train_fgsm_adv, y_train, x_test_fgsm_adv, y_test)\n",
    "ifgsm_train_acc_adv, ifgsm_test_acc_adv = evaluate(loaded_vanilla_clf_adv[0], x_train_ifgsm_adv1, y_train, x_test_ifgsm_adv1, y_test)\n",
    "df_train_acc_adv, df_test_acc_adv = evaluate(loaded_vanilla_clf_adv[0], x_train_deepfool_adv, y_train[:5000], x_test_deepfool_adv, y_test[:1000])\n",
    "cl2_train_acc_adv, cl2_test_acc_adv = evaluate(loaded_vanilla_clf_adv[0], x_train_cl2_adv, y_train[:5000], x_test_cl2_adv, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9997666666666667, 0.1134, 0.1706, 0.28828333333333334, 0.00021666666666666666) (0.994, 0.112, 0.144, 0.3052, 0.0051) (0.99995, 0.8898, 0.703, 0.24703333333333333, 0.0205) (0.9932, 0.91, 0.687, 0.2466, 0.0243) (0.9999666666666667, 0.7244, 0.6962, 0.11236666666666667, 0.11236666666666667) (0.9935, 0.75, 0.684, 0.1135, 0.1135) (0.9999333333333333, 0.971, 0.896, 0.3424333333333333, 0.7678) (0.993, 0.978, 0.894, 0.3433, 0.7639)\n"
     ]
    }
   ],
   "source": [
    "acc1 = (train_acc, df_train_acc, cl2_train_acc, fgsm_train_acc, ifgsm_train_acc)\n",
    "test_acc1 = (test_acc, df_test_acc, cl2_test_acc, fgsm_test_acc, ifgsm_test_acc)\n",
    "acc_bn1 = (train_acc_bn, df_train_acc_bn, cl2_train_acc_bn, fgsm_train_acc_bn, ifgsm_train_acc_bn)\n",
    "test_acc_bn1 = (test_acc_bn, df_test_acc_bn, cl2_test_acc_bn, fgsm_test_acc_bn, ifgsm_test_acc_bn)\n",
    "acc1_adv = (train_acc_adv, df_train_acc_adv, cl2_train_acc_adv, fgsm_train_acc_adv, ifgsm_train_acc_adv)\n",
    "test_acc1_adv = (test_acc_adv, df_test_acc_adv, cl2_test_acc_adv, fgsm_test_acc_adv, ifgsm_test_acc_adv)\n",
    "acc_bn1_adv = (train_acc_bn_adv, df_train_acc_bn_adv, cl2_train_acc_bn_adv, fgsm_train_acc_bn_adv, ifgsm_train_acc_bn_adv)\n",
    "test_acc_bn1_adv = (test_acc_bn_adv, df_test_acc_bn_adv, cl2_test_acc_bn_adv, fgsm_test_acc_bn_adv, ifgsm_test_acc_bn_adv)\n",
    "\n",
    "\n",
    "print(acc1, test_acc1, acc_bn1, test_acc_bn1, acc1_adv, test_acc1_adv, acc_bn1_adv, test_acc_bn1_adv)\n",
    "# (0.9997666666666667, 0.1134, 0.1706, 0.28828333333333334, 0.00021666666666666666) (0.994, 0.112, 0.144, 0.3052, 0.0051) (0.99995, 0.8898, 0.703, 0.24703333333333333, 0.0205) (0.9932, 0.91, 0.687, 0.2466, 0.0243) (0.9999666666666667, 0.7244, 0.6962, 0.11236666666666667, 0.11236666666666667) (0.9935, 0.75, 0.684, 0.1135, 0.1135) (0.9999333333333333, 0.971, 0.896, 0.3424333333333333, 0.7678) (0.993, 0.978, 0.894, 0.3433, 0.7639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# data to plot\n",
    "n_groups = 5\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(8,5))\n",
    "# plt.suptitle(\"Loss Sensitivity for Cifar10 models with and without Adversarial training\")\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "rects1 = plt.bar(index, acc1, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects2 = plt.bar(index + bar_width, test_acc1, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "plt.ylabel('Robustness Measure')\n",
    "ax1.set_title('CNN Without BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "rects5 = plt.bar(index, acc_bn1, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects6 = plt.bar(index + bar_width, test_acc_bn1, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "ax2.set_title('CNN With BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "rects3 = plt.bar(index, acc1_adv, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects4 = plt.bar(index + bar_width, test_acc1_adv, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "plt.xlabel('Attack Types')\n",
    "plt.ylabel('Accuracy')\n",
    "ax3.set_title('Adversarially Trained CNN Without BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "rects7 = plt.bar(index, acc_bn1_adv, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects8 = plt.bar(index + bar_width, test_acc_bn1_adv, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "plt.xlabel('Attack Types')\n",
    "ax4.set_title('Adversarially Trained CNN With BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()\n",
    "\n",
    "# plt.constrained_layout()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "def loss_sensitivity(classifier, x, y):\n",
    "    grads = classifier.loss_gradient(x, y)\n",
    "    norm = la.norm(grads.reshape(grads.shape[0], -1), ord=2, axis=1)\n",
    "    return np.mean(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_clean_bn = loss_sensitivity(loaded_vanilla_clf_with_bn[0], x_train[:3000], y_train[:3000])\n",
    "ls_df_bn = loss_sensitivity(loaded_vanilla_clf_with_bn[0], x_train_deepfool_adv[:3000], y_train[:3000])\n",
    "ls_cl2_bn = loss_sensitivity(loaded_vanilla_clf_with_bn[0], x_train_cl2_adv[:3000], y_train[:3000])\n",
    "ls_fgsm_bn = loss_sensitivity(loaded_vanilla_clf_with_bn[0], x_train_fgsm_adv[:3000], y_train[:3000])\n",
    "ls_ifgsm_bn = loss_sensitivity(loaded_vanilla_clf_with_bn[0], x_train_ifgsm_adv1[:3000], y_train[:3000])\n",
    "\n",
    "ls_clean = loss_sensitivity(loaded_vanilla_clf[0], x_train[:3000], y_train[:3000])\n",
    "ls_df = loss_sensitivity(loaded_vanilla_clf[0], x_train_deepfool_adv[:3000], y_train[:3000])\n",
    "ls_cl2 = loss_sensitivity(loaded_vanilla_clf[0], x_train_cl2_adv[:3000], y_train[:3000])\n",
    "ls_fgsm = loss_sensitivity(loaded_vanilla_clf[0], x_train_fgsm_adv[:3000], y_train[:3000])\n",
    "ls_ifgsm = loss_sensitivity(loaded_vanilla_clf[0], x_train_ifgsm_adv1[:3000], y_train[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ls_clean_bn = loss_sensitivity(loaded_vanilla_clf_with_bn_adv[0], x_train[:3000], y_train[:3000])\n",
    "adv_ls_df_bn = loss_sensitivity(loaded_vanilla_clf_with_bn_adv[0], x_train_deepfool_adv[:3000], y_train[:3000])\n",
    "adv_ls_cl2_bn = loss_sensitivity(loaded_vanilla_clf_with_bn_adv[0], x_train_cl2_adv[:3000], y_train[:3000])\n",
    "adv_ls_fgsm_bn = loss_sensitivity(loaded_vanilla_clf_with_bn_adv[0], x_train_fgsm_adv[:3000], y_train[:3000])\n",
    "adv_ls_ifgsm_bn = loss_sensitivity(loaded_vanilla_clf_with_bn_adv[0], x_train_ifgsm_adv1[:3000], y_train[:3000])\n",
    "\n",
    "adv_ls_clean = loss_sensitivity(loaded_vanilla_clf_adv[0], x_train[:3000], y_train[:3000])\n",
    "adv_ls_df = loss_sensitivity(loaded_vanilla_clf_adv[0], x_train_deepfool_adv[:3000], y_train[:3000])\n",
    "adv_ls_cl2 = loss_sensitivity(loaded_vanilla_clf_adv[0], x_train_cl2_adv[:3000], y_train[:3000])\n",
    "adv_ls_fgsm = loss_sensitivity(loaded_vanilla_clf_adv[0], x_train_fgsm_adv[:3000], y_train[:3000])\n",
    "adv_ls_ifgsm = loss_sensitivity(loaded_vanilla_clf_adv[0], x_train_ifgsm_adv1[:3000], y_train[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012740754 5.3288774 11.095702 43.53506 58.871468 0.0025929157 8.39362 13.644957 25.071657 42.407196 0.012593708 2.0581658 4.79725 116.93578 39.367527 0.0007275245 30.314804 18.210506 717.444 827.35565\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "ls_clean_bn, ls_df_bn, ls_cl2_bn, ls_fgsm_bn, ls_ifgsm_bn, \n",
    "ls_clean, ls_df, ls_cl2, ls_fgsm, ls_ifgsm,    \n",
    "adv_ls_clean_bn, adv_ls_df_bn,adv_ls_cl2_bn, adv_ls_fgsm_bn, adv_ls_ifgsm_bn, \n",
    "adv_ls_clean, adv_ls_df, adv_ls_cl2, adv_ls_fgsm, adv_ls_ifgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.012593708, 2.0581658, 4.79725, 116.93578, 39.367527) (0.0007275245, 30.314804, 18.210506, 717.444, 827.35565) (0.012740754, 5.3288774, 11.095702, 43.53506, 58.871468) (0.0025929157, 8.39362, 13.644957, 25.071657, 42.407196)\n"
     ]
    }
   ],
   "source": [
    "adv_ls_bn = (adv_ls_clean_bn, adv_ls_df_bn, adv_ls_cl2_bn, adv_ls_fgsm_bn, adv_ls_ifgsm_bn)\n",
    "adv_ls = (adv_ls_clean, adv_ls_df, adv_ls_cl2, adv_ls_fgsm, adv_ls_ifgsm)\n",
    "\n",
    "ls_bn = (ls_clean_bn, ls_df_bn, ls_cl2_bn, ls_fgsm_bn, ls_ifgsm_bn)\n",
    "ls = (ls_clean, ls_df, ls_cl2, ls_fgsm, ls_ifgsm)\n",
    "print(adv_ls_bn, adv_ls, ls_bn, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f096f97a8d0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups = 5\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(8,5))\n",
    "# plt.suptitle(\"Loss Sensitivity for Cifar10 models with and without Adversarial training\")\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "rects1 = plt.bar(index, ls, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects2 = plt.bar(index + bar_width, adv_ls, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "plt.ylabel('Loss Sensitivity')\n",
    "ax1.set_title('CNN Without BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "rects5 = plt.bar(index, ls_bn, bar_width, alpha=opacity, color='b', label='Clean training')\n",
    "rects6 = plt.bar(index + bar_width, adv_ls_bn, bar_width, alpha=opacity, color='g', label='Adversarial training')\n",
    "ax2.set_title('CNN With BatchNorm')\n",
    "plt.xticks(index + bar_width, ('No Attack', 'DF', 'CWL2', 'FGSM', 'BIM'))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
